{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Hashing for Implicit Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class LogisticRegression(MCMCLogisticRegression):',\n",
       " '    def __init__(self, m0=None, P0=None, **kwargs):',\n",
       " '        super().__init__(**kwargs)',\n",
       " '        self.m0 = m0',\n",
       " '        self.P0 = P0',\n",
       " '    def sample_from_prior(self):',\n",
       " '        return self.rng.multivariate_normal(self.m0, self.P0)',\n",
       " '    def fit(self, X, y):',\n",
       " '        P0_inv = np.linalg.inv(self.P0)',\n",
       " '        P0_inv_m0 = P0_inv.dot(self.m0)',\n",
       " '        kappas = (y - 0.5).T',\n",
       " '        XTkappa = X.T.dot(kappas)',\n",
       " '        num_predictors = X.shape[1]',\n",
       " '        beta_hat = np.ndarray((self.num_samples + 1, num_predictors))',\n",
       " '        beta_hat[0] = self.sample_from_prior()',\n",
       " '        self.beta_hat_ = beta_hat[1:]  # discard initial sample from prior',\n",
       " '        for i in range(1, self.num_samples + 1):',\n",
       " '            omegas = draw_omegas(X, beta_hat[i - 1], self.pg_rng)',\n",
       " '            V_omega = np.linalg.inv((X.T * omegas).dot(X) + P0_inv)',\n",
       " '            m_omega = V_omega.dot(XTkappa + P0_inv_m0)',\n",
       " '            beta_hat[i] = self.rng.multivariate_normal(m_omega, V_omega)',\n",
       " '        return self']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [l for l in inspect.getsource(models.LogisticRegression).split('\\n')\n",
    "         if l.strip()]\n",
    "\n",
    "\n",
    "def annotate_comments(lines):\n",
    "    in_multiline_comment = False\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        if in_multiline_comment:\n",
    "            if stripped_line.endswith('\"\"\"'):\n",
    "                in_multiline_comment = False\n",
    "            yield line, True\n",
    "        elif stripped_line.startswith('\"\"\"'):\n",
    "            if stripped_line == '\"\"\"' or not stripped_line.endswith('\"\"\"'):\n",
    "                in_multiline_comment = True\n",
    "            yield line, True\n",
    "        elif stripped_line.startswith('#'):\n",
    "            yield line, True\n",
    "        else:\n",
    "            yield line, False\n",
    "\n",
    "\n",
    "def strip_comments(lines):\n",
    "    return (line for line, is_comment in annotate_comments(lines)\n",
    "            if not is_comment)\n",
    "        \n",
    "\n",
    "list(strip_comments(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043483796943723520"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_class(klass):\n",
    "    source_lines = (l for l in inspect.getsource(klass).split('\\n')\n",
    "                    if l.strip())\n",
    "    non_comment_source = ''.join(strip_comments(source_lines))\n",
    "    return hash(non_comment_source)\n",
    "\n",
    "\n",
    "hash_class(models.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: could also implement a version of this that chains together source from all super classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual bandit OpenAI Gym Environment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 14 timesteps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "for t in range(1000):\n",
    "    env.render()\n",
    "    random_action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(random_action)\n",
    "    if done:\n",
    "        print(f\"Episode finished after {t} timesteps\")\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EnvSpec(Copy-v0),\n",
       " EnvSpec(FetchPush-v1),\n",
       " EnvSpec(AirRaidDeterministic-v4),\n",
       " EnvSpec(AsterixNoFrameskip-v4),\n",
       " EnvSpec(BattleZone-ram-v4),\n",
       " EnvSpec(Boxing-ramDeterministic-v4),\n",
       " EnvSpec(ChopperCommand-ramNoFrameskip-v4),\n",
       " EnvSpec(ElevatorAction-v4),\n",
       " EnvSpec(FrostbiteDeterministic-v4),\n",
       " EnvSpec(IceHockeyNoFrameskip-v4),\n",
       " EnvSpec(Krull-ram-v4),\n",
       " EnvSpec(NameThisGame-ramDeterministic-v4),\n",
       " EnvSpec(Pooyan-ramNoFrameskip-v4),\n",
       " EnvSpec(Robotank-v4),\n",
       " EnvSpec(SpaceInvadersDeterministic-v4),\n",
       " EnvSpec(TutankhamNoFrameskip-v4),\n",
       " EnvSpec(WizardOfWor-ram-v4)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gym.envs.registry.all())[::50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Hopper-v2',\n",
       " 'make': <bound method EnvSpec.make of EnvSpec(Hopper-v2)>,\n",
       " 'max_episode_seconds': None,\n",
       " 'max_episode_steps': 1000,\n",
       " 'nondeterministic': False,\n",
       " 'reward_threshold': 3800.0,\n",
       " 'tags': {'wrapper_config.TimeLimit.max_episode_steps': 1000},\n",
       " 'timestep_limit': 1000,\n",
       " 'trials': 100}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = gym.envs.registry.spec('Hopper-v2')\n",
    "{name: getattr(spec, name) for name in dir(spec)\n",
    " if not name.startswith('_')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new environment\n",
    "\n",
    "I've pieced together the following from reading the `openai/gym` source code.\n",
    "\n",
    "1.  A new environment can be registered by calling `gym.register(name, **kwargs)`\n",
    "    1.  The name is a unique identifier string for the environment\n",
    "    2.  The kwargs include a set of metadata. Some of this is optional. The important stuff seems to be:\n",
    "        1.  `entry_point`: Environment class or full qualified path to the class (which will be loaded dynamically)\n",
    "        2.  `trials`: number of trials to average reward over\n",
    "        3.  `kwargs`: passed through to Environment class\n",
    "        4.  `max_episode_steps`: seems to specify max number of time steps per replication / trial\n",
    "2.  Once registered, a new instance can be created by calling `gym.make(name)`\n",
    "    1.  This will create a new Environment instance by passing in `**kwargs` to `entry_point\n",
    "3.  Every `Environment` needs:\n",
    "    1.  to implement 5 methods:\n",
    "        1.  `reset()`: reset state of environment, and return initial observation\n",
    "        2.  `step(action)`: run one timestep, return tuple of `(observation, reward, done, info)`\n",
    "        3.  `seed(seed=None)`: set seed for env's RNG\n",
    "        4.  `close()`: perform any necessary cleanup operations\n",
    "        5.  `render(mode='human')`: render env if supported. This is not required, but it may be useful to implement something later on.\n",
    "    2.  to set 2-3 attributes:\n",
    "        1.  `action_space`: Space object representing valid actions\n",
    "        2.  `observation_space`: Space object representing valid observations\n",
    "        3.  (optional) `reward_range`: tuple specifying (min, max) of possible rewards, e.g. (0, 1) for binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContextualBanditEnvironment\n",
    "\n",
    "Each of our environments will be fully-characterized by:\n",
    "\n",
    "1.  Number of arms\n",
    "2.  Number of time steps\n",
    "3.  Context-generating distribution for decision instances (i.e. population characteristics)\n",
    "    -   which naturally encodes the number of context variables & covariates\n",
    "4.  True effects for each context covariate for each arm (assumed linear)\n",
    "5.  Random seed\n",
    "\n",
    "The link function will be Binomial-logistic for all our simulations for now. So rewards will be binary.\n",
    "\n",
    "The action space will be `range(num_arms)`.\n",
    "\n",
    "The observation space will correspond to the context-generating distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First environment\n",
    "\n",
    "For the first environment, we'll have:\n",
    "\n",
    "1. 10 real-valued context variables, with no interactions\n",
    "2. Homogeneous effect sizes (all same variance)\n",
    "3. 10 arms\n",
    "4. 100 time steps\n",
    "\n",
    "9 of the arms will have exactly the same effects.\n",
    "1 will have slightly better effects, so it is best for every context.\n",
    "We will generate contexts to be stricly positive to make the setting of \"better\" effects as simple as increasing any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, special\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_arms = 10\n",
    "num_time_steps = 100\n",
    "num_predictors = 10\n",
    "shared_variance = 0.5\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2440635 , 0.98305592, 0.55383303, 0.41961388, 0.09840172,\n",
       "       0.09838631, 0.03643071, 0.74959595, 0.42180713, 0.5269514 ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context-generating distribution\n",
    "dist = stats.truncnorm(0, 10, loc=0, scale=shared_variance)\n",
    "context = dist.rvs(num_predictors, random_state=rng)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6961117144835017"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.seed(42)\n",
    "effect_dist = stats.norm(0, 0.5)\n",
    "shared_effects = effect_dist.rvs(size=num_predictors, random_state=rng)\n",
    "special.expit(shared_effects.dot(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_effects = np.tile(shared_effects, 9).reshape(9, num_predictors)\n",
    "np.all(arm_effects[0] == arm_effects[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015581484856768"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_effects = shared_effects.copy()\n",
    "better_effects += stats.truncnorm.rvs(0, 0.1, loc=0, scale=0.1, size=num_predictors)\n",
    "special.expit(better_effects.dot(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82885   , 0.82885   , 0.82885   , 0.82885   , 0.82885   ,\n",
       "       0.82885   , 0.82885   , 0.82885   , 0.82885   , 0.85472868])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_effects = np.ndarray((10, 10))\n",
    "all_effects[:-1] = arm_effects\n",
    "all_effects[-1] = better_effects\n",
    "all_effects.dot(pd.Series(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = rng.binomial(n=1, p=_oh[142])\n",
    "optimal_action = rewards.argmax()\n",
    "optimal_reward = rewards[optimal_action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = gym.spaces.Box(low=0, high=np.inf, shape=(10,), dtype=np.float)\n",
    "s.contains(np.array([10] * 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Seedable\n",
    "\n",
    "\n",
    "class ContextualBanditEnv(Seedable, gym.Env):\n",
    "\n",
    "    def __init__(self, num_arms, num_predictors, num_time_steps, **kwargs):\n",
    "        Seedable.__init__(self, **kwargs)  # implements seed and reset\n",
    "\n",
    "        self.num_arms = num_arms\n",
    "        self.num_predictors = num_predictors\n",
    "        self.num_time_steps = num_time_steps\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(num_arms)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=np.inf, shape=(num_predictors,), dtype=np.float)\n",
    "        self.reward_range = (0, 1)\n",
    "\n",
    "        self._current_time_step = 0\n",
    "        self._last_observation = None\n",
    "\n",
    "        shared_variance = 0.5\n",
    "        self.context_dist = stats.truncnorm(0, 10, loc=0, scale=shared_variance)\n",
    "\n",
    "        # Set up arm effects.\n",
    "        self.arm_effects = np.ndarray((num_arms, num_predictors))\n",
    "\n",
    "        # All but one of the arms will have the same effects.\n",
    "        effect_dist = stats.norm(0, 0.5)\n",
    "        shared_effects = effect_dist.rvs(size=num_predictors, random_state=self.rng)\n",
    "        self.arm_effects[:-1] = (np.tile(shared_effects, num_arms - 1)\n",
    "                                   .reshape(num_arms - 1, num_predictors))\n",
    "\n",
    "        # The last one will have just slightly better effects.\n",
    "        self.arm_effects[-1] += shared_effects + stats.truncnorm.rvs(\n",
    "            0, 0.1, loc=0, scale=0.1, size=num_predictors, random_state=self.rng)\n",
    "\n",
    "    def _next_context(self):\n",
    "        context = self.context_dist.rvs(size=self.num_predictors, random_state=self.rng)\n",
    "        self._last_observation = pd.Series(context)\n",
    "        self._current_time_step += 1\n",
    "        return self._last_observation\n",
    "\n",
    "    def reset(self):\n",
    "        Seedable.reset(self)\n",
    "        return self._next_context()\n",
    "\n",
    "    def step(self, action):\n",
    "        rates = special.expit(self.arm_effects.dot(self._last_observation))\n",
    "        rewards = self.rng.binomial(n=1, p=rates)\n",
    "        optimal_action = rewards.argmax()\n",
    "        optimal_reward = rewards[optimal_action]\n",
    "        actual_reward = rewards[action]\n",
    "\n",
    "        info = dict(optimal_action=optimal_action,\n",
    "                    optimal_reward=optimal_reward)\n",
    "        next_observation = self._next_context()\n",
    "        done = self._current_time_step == self.num_time_steps\n",
    "        \n",
    "        return next_observation, actual_reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.register('CMABRealsOnebestN10P10T100-v4', trials=100, max_episode_steps=100,\n",
    "             entry_point=ContextualBanditEnv, kwargs=dict(\n",
    "                 num_arms=10, num_predictors=10, num_time_steps=100, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<ContextualBanditEnv<CMABRealsOnebestN10P10T100-v4>>>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmab_env = gym.envs.make('CMABRealsOnebestN10P10T100-v4')\n",
    "cmab_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 98 timesteps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = cmab_env.reset()\n",
    "\n",
    "all_rewards = np.ndarray((num_time_steps,))\n",
    "optimal_rewards = np.ndarray((num_time_steps,))\n",
    "\n",
    "for t in range(100):\n",
    "    random_action = cmab_env.action_space.sample()\n",
    "    obs, reward, done, info = cmab_env.step(random_action)\n",
    "    all_rewards[t] = reward\n",
    "    optimal_rewards[t] = info['optimal_reward']\n",
    "    if done:\n",
    "        print(f\"Episode finished after {t} timesteps\")\n",
    "        break\n",
    "\n",
    "regret = optimal_rewards - all_rewards\n",
    "np.sum(regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import plot_cum_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cum_regret(all_rewards, optimal_rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
